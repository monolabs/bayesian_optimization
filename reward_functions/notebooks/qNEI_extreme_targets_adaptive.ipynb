{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6914ce53",
   "metadata": {},
   "source": [
    "V2\n",
    "* Matern 5/2\n",
    "* 3 candidate per iteration\n",
    "* longer iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c010fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd() + '/../')\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b043e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions import Hartmann, Ackley\n",
    "\n",
    "NOISE_SE = 0.25\n",
    "train_yvar = torch.tensor(NOISE_SE**2, device=device, dtype=dtype)\n",
    "\n",
    "neg_hartmann6 = Hartmann(noise_std=NOISE_SE, negate=True)\n",
    "\n",
    "def modified_hartmann6(X: torch.Tensor)->torch.Tensor:\n",
    "    '''\n",
    "    Hartmann 6 function with x extremum shifted to [0]*6\n",
    "    '''\n",
    "    x_shift = torch.tensor([[0.20169, 0.150011, 0.476874, 0.275332, 0.311652, 0.6573]]).to(X)\n",
    "    return neg_hartmann6(X+x_shift)\n",
    "\n",
    "def modified_ackley(X: torch.Tensor)->torch.Tensor:\n",
    "    neg_ackley = Ackley(dim=6, noise_std=NOISE_SE, negate=True)\n",
    "    return neg_ackley(X*8-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f30b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition.objective import MCAcquisitionObjective, IdentityMCObjective\n",
    "from scripts.utils import *\n",
    "\n",
    "TARGET_BOUNDS_1 = [3, 3.33]\n",
    "BOUNDS_1 = [0, 4]\n",
    "\n",
    "TARGET_BOUNDS_2 = [-1, 0.0]\n",
    "BOUNDS_2 = [-12, 0.5]\n",
    "\n",
    "\n",
    "class CustomObjectiveSmooth(MCAcquisitionObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return smooth_objective(samples[..., 0], lower=TARGET_BOUNDS_1[0], upper=TARGET_BOUNDS_1[1], steepness=100)\n",
    "    def objective_2(self, samples):\n",
    "        return smooth_objective(samples[..., 1], lower=TARGET_BOUNDS_2[0], upper=TARGET_BOUNDS_2[1], steepness=100)\n",
    "    def forward(self, samples, X=None):\n",
    "        obj_1 = self.objective_1(samples)\n",
    "        obj_2 = self.objective_2(samples)\n",
    "        obj = (obj_1 + obj_2)/2\n",
    "        return obj\n",
    "    \n",
    "    \n",
    "class CustomObjectiveSharp(MCAcquisitionObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return sharp_objective(samples[..., 0], TARGET_BOUNDS_1, BOUNDS_1)\n",
    "    def objective_2(self, samples):\n",
    "        return sharp_objective(samples[..., 1], TARGET_BOUNDS_2, BOUNDS_2)\n",
    "    def forward(self, samples, X=None):\n",
    "        obj_1 = self.objective_1(samples)\n",
    "        obj_2 = self.objective_2(samples)\n",
    "        obj = (obj_1 + obj_2)/2\n",
    "        return obj\n",
    "    \n",
    "class CustomObjectiveHybrid(MCAcquisitionObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return hybrid_objective(samples[..., 0], lower=TARGET_BOUNDS_1[0], upper=TARGET_BOUNDS_1[1], steepness=0.5)\n",
    "    def objective_2(self, samples):\n",
    "        return hybrid_objective(samples[..., 1], lower=TARGET_BOUNDS_2[0], upper=TARGET_BOUNDS_2[1], steepness=0.5)\n",
    "    def forward(self, samples, X=None):\n",
    "        obj_1 = self.objective_1(samples)\n",
    "        obj_2 = self.objective_2(samples)\n",
    "        obj = (obj_1 + obj_2)/2\n",
    "        return obj\n",
    "    \n",
    "class CustomObjectiveMean(MCAcquisitionObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return samples[..., 0]\n",
    "    def objective_2(self, samples):\n",
    "        return samples[..., 1]\n",
    "    def  forward(self, samples, X=None):\n",
    "        return (self.objective_1(samples) + self.objective_2(samples))/2\n",
    "    \n",
    "\n",
    "co_smooth = CustomObjectiveSmooth()\n",
    "co_sharp = CustomObjectiveSharp()\n",
    "co_hybrid = CustomObjectiveHybrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc0e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import FixedNoiseGP, ModelListGP\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "\n",
    "CENTER_1 = (TARGET_BOUNDS_1[0] + TARGET_BOUNDS_1[1])/2\n",
    "CENTER_2 = (TARGET_BOUNDS_2[0] + TARGET_BOUNDS_2[1])/2\n",
    "X_BOUNDS = torch.tensor([[0.0] * 6, [1.0] * 6], device=device, dtype=dtype)\n",
    "KERNEL = ScaleKernel(MaternKernel(nu=2.5, ard_num_dims=6))\n",
    "\n",
    "\n",
    "def generate_initial_data(n, objective):\n",
    "    # generate training data\n",
    "    train_x = draw_sobol_samples(X_BOUNDS, 1, q=n).squeeze(0).to(device=device, dtype=dtype)\n",
    "    train_y_1 = modified_hartmann6(train_x).unsqueeze(-1)\n",
    "    train_y_2 = modified_ackley(train_x).unsqueeze(-1)\n",
    "    train_y = torch.cat([train_y_1, train_y_2], dim=-1)\n",
    "    best_observed_values = co.sharp.forward(train_y).max().item()\n",
    "    return train_x, train_y, best_observed_values\n",
    "    \n",
    "    \n",
    "def initialize_model(train_x, train_y, state_dict=None):\n",
    "    # define models for objective and constraint\n",
    "    model_obj_1 = SingleTaskGP(train_x, \n",
    "                               train_y[:, 0:1],\n",
    "                               covar_module=KERNEL,\n",
    "                               outcome_transform=Standardize(m=1)).to(train_x)\n",
    "    model_obj_2 = SingleTaskGP(train_x, \n",
    "                               train_y[:, 1:2],\n",
    "                               covar_module=KERNEL,\n",
    "                               outcome_transform=Standardize(m=1)).to(train_x)\n",
    "    # combine into a multi-output GP model\n",
    "    model = ModelListGP(model_obj_1, model_obj_2)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    # load state dict if it is passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d5d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "NUM_RESTARTS = 20\n",
    "RAW_SAMPLES = 512\n",
    "\n",
    "\n",
    "def optimize_acqf_and_get_observation(model, train_x, objective):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\n",
    "    # acqf\n",
    "    qNEI = qNoisyExpectedImprovement(\n",
    "            model=model, \n",
    "            X_baseline=train_x,\n",
    "            sampler=qmc_sampler, \n",
    "            objective=objective,\n",
    "        )\n",
    "    \n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=qNEI,\n",
    "        bounds=X_BOUNDS,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    # observe new values \n",
    "    new_x = candidates.detach()\n",
    "    new_y_1 = neg_hartmann6(new_x).unsqueeze(-1)  # add output dimension\n",
    "    new_y_2 = modified_ackley(new_x).unsqueeze(-1)  # add output dimension\n",
    "    new_y = torch.cat([new_y_1, new_y_2], dim=-1)\n",
    "    return new_x, new_y\n",
    "\n",
    "\n",
    "def update_random_observations(best_random, objective):\n",
    "    \"\"\"Simulates a random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    \"\"\"\n",
    "    rand_x = torch.rand(BATCH_SIZE, 6)\n",
    "    rand_y_1 = modified_hartmann6(rand_x).unsqueeze(-1)  # add output dimension\n",
    "    rand_y_2 = modified_ackley(rand_x).unsqueeze(-1)  # add output dimension\n",
    "    rand_y = torch.cat([rand_y_1, rand_y_2], dim=-1)\n",
    "    next_random_best = objective.forward(rand_y).max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85046e99",
   "metadata": {},
   "source": [
    "### BO Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f09fed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 20 ......................................................................................................................................................\n",
      "Trial  2 of 20 ......................................................................................................................................................\n",
      "Trial  3 of 20 ......................................................................................................................................................\n",
      "Trial  4 of 20 ......................................................................................................................................................\n",
      "Trial  5 of 20 ......................................................................................................................................................\n",
      "Trial  6 of 20 ......................................................................................................................................................\n",
      "Trial  7 of 20 ......................................................................................................................................................\n",
      "Trial  8 of 20 ......................................................................................................................................................\n",
      "Trial  9 of 20 ......................................................................................................................................................\n",
      "Trial 10 of 20 ......................................................................................................................................................\n",
      "Trial 11 of 20 ......................................................................................................................................................\n",
      "Trial 12 of 20 ......................................................................................................................................................\n",
      "Trial 13 of 20 ......................................................................................................................................................\n",
      "Trial 14 of 20 ......................................................................................................................................................\n",
      "Trial 15 of 20 ......................................................................................................................................................\n",
      "Trial 16 of 20 ......................................................................................................................................................\n",
      "Trial 17 of 20 ......................................................................................................................................................\n",
      "Trial 18 of 20 ......................................................................................................................................................\n",
      "Trial 19 of 20 ......................................................................................................................................................\n",
      "Trial 20 of 20 ......................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "N_TRIALS = 3\n",
    "N_BATCH = 20\n",
    "MC_SAMPLES = 512\n",
    "\n",
    "verbose = False\n",
    "\n",
    "best_observed_all_smooth, best_observed_all_sharp, best_observed_all_hybrid = [], [], []\n",
    "\n",
    "\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    \n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    best_observed_smooth, best_observed_sharp, best_observed_hybrid = [], [], []\n",
    "    \n",
    "    # call helper functions to generate initial training data and initialize model\n",
    "    train_x_smooth, train_y_smooth, best_observed_value_smooth = generate_initial_data(10, co_smooth)\n",
    "    mll_smooth, model_smooth = initialize_model(train_x_smooth, train_y_smooth)\n",
    "    \n",
    "    train_x_sharp, train_y_sharp = train_x_smooth, train_y_smooth\n",
    "    best_observed_value_sharp = best_observed_value_smooth\n",
    "    mll_sharp, model_sharp = initialize_model(train_x_sharp, train_y_sharp)\n",
    "    \n",
    "    train_x_hybrid, train_y_hybrid = train_x_smooth, train_y_smooth\n",
    "    best_observed_value_hybrid = best_observed_value_smooth\n",
    "    mll_hybrid, model_hybrid = initialize_model(train_x_sharp, train_y_sharp)\n",
    "    \n",
    "    best_observed_smooth.append(best_observed_value_smooth)\n",
    "    best_observed_sharp.append(best_observed_value_sharp)\n",
    "    best_observed_hybrid.append(best_observed_value_hybrid)\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        # fit the models\n",
    "        fit_gpytorch_model(mll_smooth)\n",
    "        fit_gpytorch_model(mll_sharp)\n",
    "        fit_gpytorch_model(mll_hybrid)\n",
    "        \n",
    "        # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "        qmc_sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
    "        \n",
    "        # optimize and get new observation\n",
    "        new_x_smooth, new_y_smooth = optimize_acqf_and_get_observation(model_smooth, train_x_smooth, co_smooth)\n",
    "        new_x_sharp, new_y_sharp = optimize_acqf_and_get_observation(model_sharp, train_x_sharp, co_sharp)\n",
    "        new_x_hybrid, new_y_hybrid = optimize_acqf_and_get_observation(model_hybrid, train_x_hybrid, co_hybrid)\n",
    "                \n",
    "        # update training points\n",
    "        train_x_smooth = torch.cat([train_x_smooth, new_x_smooth])\n",
    "        train_y_smooth = torch.cat([train_y_smooth, new_y_smooth])\n",
    "\n",
    "        train_x_sharp = torch.cat([train_x_sharp, new_x_sharp])\n",
    "        train_y_sharp = torch.cat([train_y_sharp, new_y_sharp])\n",
    "        \n",
    "        train_x_hybrid = torch.cat([train_x_hybrid, new_x_hybrid])\n",
    "        train_y_hybrid = torch.cat([train_y_hybrid, new_y_hybrid])\n",
    "\n",
    "        # update progress\n",
    "        best_value_smooth = co_sharp.forward(train_y_smooth).max().item()   # both use sharp to compute best values\n",
    "        best_value_sharp = co_sharp.forward(train_y_sharp).max().item()    # both use sharp to compute best values\n",
    "        best_value_hybrid = co_sharp.forward(train_y_hybrid).max().item()    # both use sharp to compute best values\n",
    "        \n",
    "        best_observed_smooth.append(best_value_smooth)\n",
    "        best_observed_sharp.append(best_value_sharp)\n",
    "        best_observed_hybrid.append(best_value_hybrid)\n",
    "\n",
    "        # reinitialize the models so they are ready for fitting on next iteration\n",
    "        # use the current state dict to speed up fitting\n",
    "        mll_smooth, model_smooth = initialize_model(\n",
    "            train_x_smooth, \n",
    "            train_y_smooth, \n",
    "            model_smooth.state_dict(),\n",
    "        )\n",
    "        mll_sharp, model_sharp = initialize_model(\n",
    "            train_x_sharp, \n",
    "            train_y_sharp, \n",
    "            model_sharp.state_dict(),\n",
    "        )\n",
    "        mll_hybrid, model_hybrid = initialize_model(\n",
    "            train_x_hybrid, \n",
    "            train_y_hybrid, \n",
    "            model_hybrid.state_dict(),\n",
    "        )\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: best_value (qNEI_smooth, qNEI_sharp, qNEI_hybrid) = \"\n",
    "                f\"( {best_value_smooth:>4.2f}, {best_value_sharp:>4.2f}, {best_value_hybrid:>4.2f}), \"\n",
    "                f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "            )\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "   \n",
    "    best_observed_all_smooth.append(best_observed_smooth)\n",
    "    best_observed_all_sharp.append(best_observed_sharp)\n",
    "    best_observed_all_hybrid.append(best_observed_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575c51f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_BATCH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-05c2543aba0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_BATCH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0my_smooth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_observed_all_smooth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0my_sharp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_observed_all_sharp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N_BATCH' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "\n",
    "GLOBAL_MAXIMUM = 1.0\n",
    "\n",
    "\n",
    "iters = np.arange(N_BATCH + 1) * BATCH_SIZE\n",
    "y_smooth = np.asarray(best_observed_all_smooth)\n",
    "y_sharp = np.asarray(best_observed_all_sharp)\n",
    "y_hybrid = np.asarray(best_observed_all_hybrid)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "# ax.errorbar(iters, y_rnd_smooth.mean(axis=0), yerr=ci(y_rnd_smooth), label=\"random_smooth\", linewidth=1.5, alpha=0.5)\n",
    "ax.errorbar(iters, y_smooth.mean(axis=0), yerr=ci(y_smooth), label=\"qNEI_smooth\", linewidth=2.5, alpha=0.5)\n",
    "ax.errorbar(iters, y_sharp.mean(axis=0), yerr=ci(y_sharp), label=\"qNEI_sharp\", linewidth=1.5, alpha=0.5)\n",
    "ax.errorbar(iters, y_hybrid.mean(axis=0), yerr=ci(y_hybrid), label=\"qNEI_hybrid\", linewidth=1.5, alpha=0.5)\n",
    "plt.plot([0, N_BATCH * BATCH_SIZE], [GLOBAL_MAXIMUM] * 2, 'k', label=\"true best objective\", linewidth=2)\n",
    "ax.set_ylim(bottom=0.0, top=0.8)\n",
    "ax.set(xlabel='number of observations (beyond initial points)', ylabel='best objective value')\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece2487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bo)",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
