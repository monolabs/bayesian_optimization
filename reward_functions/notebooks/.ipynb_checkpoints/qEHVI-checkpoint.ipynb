{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0195cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd() + '/../')\n",
    "\n",
    "import torch\n",
    "\n",
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1006656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.multi_objective import BraninCurrin\n",
    "\n",
    "problem = BraninCurrin(negate=True).to(**tkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ceebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "\n",
    "\n",
    "def generate_initial_data(n=6):\n",
    "    # generate training data\n",
    "    train_x = draw_sobol_samples(\n",
    "        bounds=problem.bounds,n=1, q=n, seed=torch.randint(1000000, (1,)).item()\n",
    "    ).squeeze(0)\n",
    "    train_obj = problem(train_x)\n",
    "    return train_x, train_obj\n",
    "\n",
    "\n",
    "def initialize_model(train_x, train_obj):\n",
    "    # define models for objective and constraint\n",
    "    model = SingleTaskGP(train_x, train_obj, outcome_transform=Standardize(m=train_obj.shape[-1]))\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47b4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom objective\n",
    "from botorch.acquisition.multi_objective.objective import MCMultiOutputObjective\n",
    "from scripts.objectives import *\n",
    "\n",
    "TARGET_BOUNDS_1 = [-2, -1]\n",
    "BOUNDS_1 = [-14, 0]\n",
    "\n",
    "TARGET_BOUNDS_2 = [-20, -10]\n",
    "BOUNDS_2 = [-250, 0]\n",
    "\n",
    "class CustomObjectiveSmooth(MCMultiOutputObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return smooth_objective(samples[..., 0], lower=TARGET_BOUNDS_1[0], upper=TARGET_BOUNDS_1[1], steepness=100)\n",
    "    def objective_2(self, samples):\n",
    "        return smooth_objective(samples[..., 1], lower=TARGET_BOUNDS_2[0], upper=TARGET_BOUNDS_2[1], steepness=100)\n",
    "    def forward(self, samples, X=None):\n",
    "        obj_1 = self.objective_1(samples)\n",
    "        obj_2 = self.objective_2(samples)\n",
    "        obj = torch.cat([obj_1.unsqueeze(-1), obj_2.unsqueeze(-1)], dim=-1)\n",
    "        return obj\n",
    "    \n",
    "    \n",
    "class CustomObjectiveSharp(MCMultiOutputObjective):\n",
    "    \n",
    "    def objective_1(self, samples):\n",
    "        return sharp_objective(samples[..., 0], TARGET_BOUNDS_1, BOUNDS_1)\n",
    "    def objective_2(self, samples):\n",
    "        return sharp_objective(samples[..., 1], TARGET_BOUNDS_2, BOUNDS_2)\n",
    "    def forward(self, samples, X=None):\n",
    "        obj_1 = self.objective_1(samples)\n",
    "        obj_2 = self.objective_2(samples)\n",
    "        obj = torch.cat([obj_1.unsqueeze(-1), obj_2.unsqueeze(-1)], dim=-1)\n",
    "        return obj\n",
    "    \n",
    "\n",
    "co_smooth = CustomObjectiveSmooth()\n",
    "co_sharp = CustomObjectiveSharp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068c2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n",
    "from botorch.acquisition.objective import GenericMCObjective\n",
    "from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import NondominatedPartitioning\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
    "from botorch.utils.sampling import sample_simplex\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4 if not SMOKE_TEST else 2\n",
    "NUM_RESTARTS = 20 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 1024 if not SMOKE_TEST else 4\n",
    "\n",
    "standard_bounds = torch.zeros(2, problem.dim, **tkwargs)\n",
    "standard_bounds[1] = 1\n",
    "\n",
    "\n",
    "def optimize_qehvi_and_get_observation(model, train_obj, objective, sampler):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    # partition non-dominated space into disjoint rectangles\n",
    "    partitioning = NondominatedPartitioning(ref_point=problem.ref_point, Y=train_obj)\n",
    "    acq_func = qExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=problem.ref_point.tolist(),  # use known reference point \n",
    "        partitioning=partitioning,\n",
    "        objective=objective,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=standard_bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200, \"nonnegative\": True},\n",
    "        sequential=True,\n",
    "    )\n",
    "    # observe new values \n",
    "    new_x =  unnormalize(candidates.detach(), bounds=problem.bounds)\n",
    "    new_obj = problem(new_x)\n",
    "    return new_x, new_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1493ab",
   "metadata": {},
   "source": [
    "### BO Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4483eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 3 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "10 elements of the 10 element gradient array `gradf` are NaN. This often indicates numerical issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dc4c1a920dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# optimize acquisition functions and get new observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         new_x_smooth, new_obj_smooth = optimize_qehvi_and_get_observation(\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mmodel_smooth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_obj_smooth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mco_smooth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmooth_sampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         )\n",
      "\u001b[1;32m<ipython-input-5-82dedc5a5d46>\u001b[0m in \u001b[0;36moptimize_qehvi_and_get_observation\u001b[1;34m(model, train_obj, objective, sampler)\u001b[0m\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     candidates, _ = optimize_acqf(\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0macq_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstandard_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\botorch\\optim\\optimize.py\u001b[0m in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mbase_X_pending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macq_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_pending\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             candidate, acq_value = optimize_acqf(\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[0macq_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\botorch\\optim\\optimize.py\u001b[0m in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mend_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_restarts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# optimize using random restart optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         batch_candidates_curr, batch_acq_values_curr = gen_candidates_scipy(\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0minitial_conditions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_initial_conditions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0macquisition_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\botorch\\generation\\gen.py\u001b[0m in \u001b[0;36mgen_candidates_scipy\u001b[1;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, options, fixed_features)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     res = minimize(\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\bo\\lib\\site-packages\\botorch\\generation\\gen.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minitial_conditions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\" Consider using `dtype=torch.double`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mfval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 10 elements of the 10 element gradient array `gradf` are NaN. This often indicates numerical issues."
     ]
    }
   ],
   "source": [
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "N_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "N_BATCH = 25 if not SMOKE_TEST else 3\n",
    "MC_SAMPLES = 128  if not SMOKE_TEST else 16\n",
    "\n",
    "verbose = False\n",
    "\n",
    "hvs_smooth, hvs_sharp, hvs_random_all = [], [], []\n",
    "\n",
    "hv = Hypervolume(ref_point=problem.ref_point)\n",
    "\n",
    "\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    torch.manual_seed(trial)\n",
    "    \n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    hvs_smooth, hvs_sharp, hvs_random = [], [], []\n",
    "    \n",
    "    # call helper functions to generate initial training data and initialize model\n",
    "    train_x_smooth, train_obj_smooth = generate_initial_data(n=6)\n",
    "    mll_smooth, model_smooth = initialize_model(train_x_smooth, train_obj_smooth)\n",
    "    \n",
    "    train_x_sharp, train_obj_sharp = train_x_smooth, train_obj_smooth\n",
    "    train_x_random, train_obj_random = train_x_smooth, train_obj_smooth\n",
    "    # compute hypervolume \n",
    "    mll_sharp, model_sharp = initialize_model(train_x_sharp, train_obj_sharp)\n",
    "    \n",
    "    # compute pareto front\n",
    "    pareto_mask = is_non_dominated(train_obj_smooth)\n",
    "    pareto_y = train_obj_smooth[pareto_mask]\n",
    "    # compute hypervolume\n",
    "    \n",
    "    volume = hv.compute(pareto_y)\n",
    "    \n",
    "    hvs_smooth.append(volume)\n",
    "    hvs_sharp.append(volume)\n",
    "    hvs_random.append(volume)\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        # fit the models\n",
    "        fit_gpytorch_model(mll_smooth)\n",
    "        fit_gpytorch_model(mll_sharp)\n",
    "        \n",
    "        # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "        smooth_sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
    "        sharp_sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
    "        \n",
    "        # optimize acquisition functions and get new observations\n",
    "        new_x_smooth, new_obj_smooth = optimize_qehvi_and_get_observation(\n",
    "            model_smooth, train_obj_smooth, co_smooth, smooth_sampler\n",
    "        )\n",
    "        new_x_sharp, new_obj_sharp = optimize_qehvi_and_get_observation(\n",
    "            model_sharp, train_obj_sharp, co_sharp, sharp_sampler\n",
    "        )\n",
    "        new_x_random, new_obj_random = generate_initial_data(n=BATCH_SIZE)\n",
    "                \n",
    "        # update training points\n",
    "        train_x_smooth = torch.cat([train_x_smooth, new_x_smooth])\n",
    "        train_obj_smooth = torch.cat([train_obj_smooth, new_obj_smooth])\n",
    "\n",
    "        train_x_sharp = torch.cat([train_x_sharp, new_x_sharp])\n",
    "        train_obj_sharp = torch.cat([train_obj_sharp, new_obj_sharp])\n",
    "    \n",
    "        train_x_random = torch.cat([train_x_random, new_x_random])\n",
    "        train_obj_random = torch.cat([train_obj_random, new_obj_random])\n",
    "        \n",
    "\n",
    "        # update progress\n",
    "        for hvs_list, train_obj in zip(\n",
    "            (hvs_random, hvs_smooth, hvs_sharp), \n",
    "            (train_obj_random, train_obj_smooth, train_obj_sharp),\n",
    "        ):\n",
    "            # compute pareto front\n",
    "            pareto_mask = is_non_dominated(train_obj)\n",
    "            pareto_y = train_obj[pareto_mask]\n",
    "            # compute hypervolume\n",
    "            volume = hv.compute(pareto_y)\n",
    "            hvs_list.append(volume)\n",
    "\n",
    "        # reinitialize the models so they are ready for fitting on next iteration\n",
    "        # Note: we find improved performance from not warm starting the model hyperparameters\n",
    "        # using the hyperparameters from the previous iteration\n",
    "        mll_smooth, model_smooth = initialize_model(train_x_smooth, train_obj_smooth)\n",
    "        mll_sharp, model_sharp = initialize_model(train_x_sharp, train_obj_sharp)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: Hypervolume (random, smooth, sharp) = \"\n",
    "                f\"({hvs_random[-1]:>4.2f}, {hvs_smooth[-1]:>4.2f}, {hvs_sharp[-1]:>4.2f}), \"\n",
    "                f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "            )\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "   \n",
    "    hvs_smooth_all.append(hvs_smooth)\n",
    "    hvs_sharp_all.append(hvs_sharp)\n",
    "    hvs_random_all.append(hvs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[-9.5, -95],\n",
    "                  [0, -100],\n",
    "                  [-10, 0]])\n",
    "co_smooth.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e267b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_sharp.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213865ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bo)",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
